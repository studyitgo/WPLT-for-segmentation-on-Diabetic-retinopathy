{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18deabd8",
   "metadata": {},
   "source": [
    "# Segmentation Exudatae, Red Dot（+MA） and Hemorrage from IDRiD dataset and DIARETDB1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8431f6",
   "metadata": {},
   "source": [
    "Compiler (Adam)\n",
    "Learning rate (0.00005)\n",
    "Accuracy metric: Dice coefficient [9] to be maximized\n",
    "Loss metric: negative Dice coefficient (to be minimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import keras.backend as K\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "WIDTH, HEIGHT = 1024, 1024\n",
    "# NUM_CLASSES = 3 # 0. Background, 1, Exudatas(Hard + Soft), 2. Red Dot + Hemorrhages + Microaneurysms\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "EPOCHS = 10# 50\n",
    "\n",
    "# On Colab\n",
    "# MODEL_DIR = \"./Diabetic Retinopathy/\"\n",
    "# BASE_DIR = 'F:\\hcc\\A. Segmentation\\A. Segmentation/'\n",
    "\n",
    "# On windows Os\n",
    "MODEL_DIR = \"./Diabetic Retinopathy/\"# \"C:/Users/yhu04/Diabetic Retinopathy/\"\n",
    "BASE_DIR = \"./DR_data/\"\n",
    "psi = [1]*5\n",
    "NUM_CLASSES = 3# 3\n",
    "category_types = [\"Background\", \"EX\", \"RHM\"]\n",
    "background = [255,255,255]\n",
    "ex = [128,128,0]\n",
    "rhm = [255,0,0]\n",
    "label_colours = np.array([background,ex,rhm])\n",
    "def visualize(temp, plot=True):\n",
    "    r = temp.copy()\n",
    "    g = temp.copy()\n",
    "    b = temp.copy()\n",
    "    for l in range(0,3):\n",
    "        r[temp==l]=label_colours[l,0]\n",
    "        g[temp==l]=label_colours[l,1]\n",
    "        b[temp==l]=label_colours[l,2]\n",
    "\n",
    "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
    "    rgb[:,:,0] = (r/255.0)#[:,:,0]\n",
    "    rgb[:,:,1] = (g/255.0)#[:,:,1]\n",
    "    rgb[:,:,2] = (b/255.0)#[:,:,2]\n",
    "    if plot:\n",
    "        plt.imshow(rgb)\n",
    "    else:\n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcb1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone(width = WIDTH, height = HEIGHT):\n",
    "    backbone = keras.applications.VGG16(include_top=False, input_shape=(width, height, 3), weights = \"imagenet\")\n",
    "    output_0, output_1, output_2, output_3, output_4, fin_output = [\n",
    "        backbone.get_layer(layer_name).output\n",
    "        for layer_name in [\"block1_conv2\",\"block2_conv2\", \"block3_conv3\", \"block4_conv3\", \"block5_conv3\", \"block5_pool\"]\n",
    "    ]\n",
    "   \n",
    "        \n",
    "    return keras.Model(\n",
    "        inputs=[backbone.inputs],\n",
    "        outputs=[ fin_output, output_4, output_3, output_2, output_1, output_0 ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f31e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twice_Conv2D(input_image, num_filters, i):\n",
    "    for j in range(2):\n",
    "        output = keras.layers.Conv2D(num_filters, 3, 1, \n",
    "                                    padding = \"same\",\n",
    "                                    kernel_initializer='he_normal',\n",
    "                                    name=f\"ccblock{i+1}_Conv{j+1}\")(input_image)\n",
    "        \n",
    "        output = keras.layers.BatchNormalization(name=f\"ccblock{i+1}_BN{j+1}\")(output)\n",
    "        output = keras.layers.ReLU(name = f\"ccblock{i+1}_ReLU{j+1}\")(output)\n",
    "#         print(output.shape)\n",
    "        \n",
    "    return output\n",
    "\n",
    "    \n",
    "    \n",
    "def Unet(psi = psi, num_classes = NUM_CLASSES, width = WIDTH, height = HEIGHT): \n",
    "    \n",
    "    input_image = keras.Input(shape=(width, height, 3), name=\"ccinput\")\n",
    "\n",
    "    output_list = get_backbone()(input_image, training = False)  \n",
    "    output = output_list[0]# 即fin_output\n",
    "    \n",
    "    outC = keras.layers.MaxPool2D(32,32)(output)\n",
    "    outC = keras.layers.Flatten(name='ccflatten')(outC)\n",
    "    outC = keras.layers.Dense(units=32)(outC)\n",
    "    outC = keras.layers.ReLU()(outC)\n",
    "    outC = keras.layers.Dense(units=int(np.sum(psi)),activation=\"softmax\",name=f\"grad\")(outC)\n",
    "#     print(outC.shape)# (None,5)?or 3\n",
    "    \n",
    "    for i in range(2):\n",
    "        output = keras.layers.Conv2D(512, 3, 1, \n",
    "                                     padding = \"same\",\n",
    "                                     kernel_initializer='he_normal',\n",
    "                                     name=f\"ccblock{0}_Conv{i}\")(output)\n",
    "        output = keras.layers.BatchNormalization(name=f\"ccblock{0}_BN{i}\")(output)\n",
    "        output = keras.layers.ReLU(name=f\"ccblock{0}_ReLU{i}\")(output)\n",
    "          \n",
    "    for i, filters in enumerate([256, 128, 64, 32, 16]):\n",
    "        output = keras.layers.UpSampling2D(2, name=f\"ccblock{i+1}_UpSampling{0}\")(output)\n",
    "\n",
    "        output = keras.layers.Conv2D(output.shape[-1], 2, 1, \n",
    "                                     padding = \"same\",\n",
    "                                     kernel_initializer='he_normal',\n",
    "                                     name=f\"ccblock{i+1}_Conv{0}\")(output)\n",
    "\n",
    "        output = keras.layers.BatchNormalization(name=f\"ccblock{i+1}_BN{0}\")(output)\n",
    "        output = keras.layers.ReLU(name=f\"ccblock{i+1}_ReLU{0}\")(output)\n",
    "        output = keras.layers.concatenate([output, output_list[i+1]], name = f\"ccblock{i+1}_concat\")\n",
    "        output = twice_Conv2D(output, filters, i)\n",
    "\n",
    "                \n",
    "    output = keras.layers.Conv2D(num_classes, 1, 1, \n",
    "                                 padding = \"same\", \n",
    "                                 activation = \"softmax\", \n",
    "                                 kernel_initializer=tf.initializers.RandomNormal(0.0, 0.01),\n",
    "                                 bias_initializer = tf.constant_initializer(-np.log((1 - 0.01) / 0.01)),\n",
    "                                 name = f\"grad{5}_Conv_ReLU\")(output)\n",
    "    \n",
    "    # (None, 1024, 1024, 3)\n",
    "    \n",
    "    model = keras.models.Model(inputs = input_image, outputs=[output,outC])\n",
    "    return model\n",
    "# Unet(3,1024,1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_softmax(x,mask):\n",
    "    logits = tf.exp(x) * mask / tf.reduce_sum(tf.exp(x) * mask)\n",
    "#     print(logits)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf58fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label = [0,1]\n",
    "img = tf.keras.Input(shape=(1024, 1024, 3), name=\"ccinput\")\n",
    "grad = [2]\n",
    "def LabelGenerator(x,y,class_nb = psi,num_classes = NUM_CLASSES,batch_size = BATCH_SIZE):\n",
    "   \n",
    "    filters = [64,128,256,512,512]\n",
    "#     x = np.reshape(x, ((batch_size,) + x.shape))\n",
    "#     print(\"encoder:\",input_image.shape)# encoder: (None, 1024, 1024, 3)\n",
    "    output_list = get_backbone()(x, training = False)  \n",
    "    output = output_list[0]# 即fin_output\n",
    "    \n",
    "    outC = keras.layers.MaxPool2D(32,32)(output)\n",
    "    outC = keras.layers.Flatten(name='ccflatten')(outC)\n",
    "    outC = keras.layers.Dense(units=32)(outC)\n",
    "    outC = keras.layers.ReLU()(outC)\n",
    "    outC = keras.layers.Dense(units=int(np.sum(psi)),activation=\"softmax\",name=f\"classfc\")(outC)\n",
    "    \n",
    "    \n",
    "    index = tf.zeros([len(class_nb),np.sum(class_nb)]) + 1e-8\n",
    "    index = index.numpy()\n",
    "    \n",
    "    for i in range(len(class_nb)):\n",
    "        index[i, int(np.sum(class_nb[:i])):np.sum(class_nb[:i+1])] = 1\n",
    "    \n",
    "    index = tf.convert_to_tensor(index)\n",
    "#     print(index)\n",
    "#     print(y)# [3]\n",
    "    mask = index[y]\n",
    "#     print(mask)# tf.Tensor([1.e-08 1.e-08 1.e-08 1.e+00 1.e-08], shape=(5,), dtype=float32) grad=[3]\n",
    "    \n",
    "    \n",
    "    classifier = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(filters[-1]),\n",
    "        tf.keras.layers.ReLU(),\n",
    "        tf.keras.layers.Dense(filters[-1]),\n",
    "        \n",
    "    ])\n",
    "    \n",
    "#     predict.shape (1, 512)\n",
    "#     mask.shape (5,)\n",
    "#     print(\"outC.shape\",outC.shape)\n",
    "    label_pred = mask_softmax(outC, mask)\n",
    "#     print(label_pred.shape)# (None, 5)\n",
    "\n",
    "    return label_pred  \n",
    "LabelGenerator(img,grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489082ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dice(y_true, y_pred, solo = True, num_classes = NUM_CLASSES):\n",
    "   \n",
    "    smooth = 0.0001# 0.0001\n",
    "    if solo:\n",
    "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32),\n",
    "                            depth=num_classes,\n",
    "                            dtype=tf.float32,\n",
    "                            )\n",
    "    \n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    \n",
    "    return (numerator + smooth) / (denominator + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_info(n_cl, pred, gt):\n",
    "    assert (pred.shape == gt.shape)  \n",
    "    k = (gt >= 0) & (gt < n_cl)  \n",
    "    labeled = np.sum(k)  \n",
    "    correct = np.sum((pred[k] == gt[k]))  \n",
    "\n",
    "    return np.bincount(n_cl * gt[k].astype(int) + pred[k].astype(int),\n",
    "                       minlength=n_cl ** 2).reshape(n_cl, n_cl), labeled, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba7144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dice_class(y_true, y_pred, solo = True, num_classes = 5):\n",
    "    smooth = 0.0001# 0.0001\n",
    "    if solo:\n",
    "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32),\n",
    "                            depth=num_classes,\n",
    "                            dtype=tf.float32,\n",
    "                            )\n",
    "        \n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "    return (numerator + smooth) / (denominator + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify_ac(y_true, y_pred,solo = True, num_classes = 5):\n",
    "    if solo:\n",
    "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32),\n",
    "                            depth=num_classes,\n",
    "                            dtype=tf.float32,\n",
    "                            )\n",
    "    correct_predict = tf.equal(tf.argmax(y_pred, 0), tf.argmax(y_true, 0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, 'float'))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c54c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalFocalLoss(tf.losses.Loss):\n",
    "    \"\"\"\n",
    "    公式 : loss = - y_true * alpha * ((1 - y_pred)^gamma) * log(y_pred)\n",
    "        \n",
    "    alpha: the same as weighting factor in balanced cross entropy, default 0.25\n",
    "    gamma: focusing parameter for modulating factor (1-p), default 2.0\n",
    "\n",
    "    y_true =  [[0., 1.0, 0.], [0., 0., 1.], [0., 1., 0.]]\n",
    "    y_pred = [[0.70, 0.15, 0.15], [0.1, 0.8, 0.1], [0.25, 0.65, 0.1]]\n",
    "    y_true = tf.cast(y_true, dtype= \"float32\")\n",
    "    y_pred = tf.cast(y_pred, dtype= \"float32\")\n",
    "    gamma=3.0\n",
    "    alpha=0.25\n",
    "    \"\"\"\n",
    "    def __init__(self, solo = True, num_classes = NUM_CLASSES, gamma = 2.0, alpha=0.25):\n",
    "        super(CategoricalFocalLoss, self).__init__(reduction = 'auto', name = \"CategoricalFocalLoss\")\n",
    "        self._num_classes = num_classes\n",
    "        self._gamma = gamma\n",
    "        self._alpha = alpha\n",
    "        self._epsilon = 1e-07\n",
    "        self.solo = solo\n",
    "        \n",
    "        \n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "      \n",
    "        if self.solo:\n",
    "            y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32),\n",
    "                                depth=self._num_classes,\n",
    "                                dtype=tf.float32,\n",
    "                                )\n",
    "         \n",
    "        y_pred = tf.clip_by_value(y_pred, self._epsilon, 1.0 - self._epsilon)\n",
    "        loss = - y_true * self._alpha * tf.math.pow((1 - y_pred), self._gamma) * tf.math.log(y_pred)\n",
    "        \"\"\"\n",
    "        Another Code\n",
    "        alpha = tf.where(tf.equal(y_true, 1.), alpha, (1.0 - self._alpha))\n",
    "        pt = tf.where(tf.equal(y_true, 1.), y_pred, 1-y_pred)\n",
    "        y_pred = tf.add(y_pred, self._epsilon)\n",
    "        loss = alpha * tf.pow(1.0 - pt, self._gamma) * tf.multiply(y_true, -tf.math.log(y_pred))\n",
    "        \"\"\"\n",
    "#      \n",
    "        return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9787888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalFocalLoss2(tf.losses.Loss):\n",
    "   \n",
    "    def __init__(self, solo = True, num_classes = 5, gamma = 2.0, alpha=0.25):\n",
    "        super(CategoricalFocalLoss2, self).__init__( name = \"CategoricalFocalLoss2\")# reduction = 'auto',\n",
    "        self._num_classes = num_classes\n",
    "        self._gamma = gamma\n",
    "        self._alpha = alpha\n",
    "        self._epsilon = 1e-07\n",
    "        self.solo = solo\n",
    "        \n",
    "        \n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "      \n",
    "        if self.solo:\n",
    "            y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32),\n",
    "                                depth=self._num_classes,\n",
    "                                dtype=tf.float32,\n",
    "                                )\n",
    "         \n",
    "        y_pred = tf.clip_by_value(y_pred, self._epsilon, 1.0 - self._epsilon)\n",
    "        loss = - y_true * self._alpha * tf.math.pow((1 - y_pred), self._gamma) * tf.math.log(y_pred)\n",
    "       \n",
    "        return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c934b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_dice_coef_fun(smooth=0, solo=True):\n",
    "    def generalized_dice(y_true, y_pred):\n",
    "        # Compute weights: \"the contribution of each label is corrected by the inverse of its volume\"\n",
    "        if solo:\n",
    "            y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32),\n",
    "                                depth=NUM_CLASSES,\n",
    "                                dtype=tf.float32,\n",
    "                                )\n",
    "        w = K.sum(y_true, axis=(0, 1, 2))\n",
    "        w = 1 / (w ** 2 + 0.00001)\n",
    "      \n",
    "        # Compute gen dice coef:\n",
    "        numerator = y_true * y_pred\n",
    "        numerator = w * K.sum(numerator, axis=(0, 1, 2))\n",
    "        numerator = K.sum(numerator)\n",
    " \n",
    "        denominator = y_true + y_pred\n",
    "        denominator = w * K.sum(denominator, axis=(0, 1, 2))\n",
    "        denominator = K.sum(denominator)\n",
    " \n",
    "        gen_dice_coef = numerator / denominator\n",
    " \n",
    "        return  2 * gen_dice_coef\n",
    "    return generalized_dice\n",
    " \n",
    "def generalized_dice_loss_fun(smooth=0):\n",
    "    def generalized_dice_loss(y_true,y_pred):\n",
    "        return 1 - generalized_dice_coef_fun(smooth=smooth)(y_true=y_true,y_pred=y_pred)\n",
    "    return generalized_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = lambda y: y\n",
    "def cont_kappa(y_true, y_pred, activation=None):\n",
    "    ''' continuos version of quadratic weighted kappa '''\n",
    "    y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32),\n",
    "                                depth=self.num_class,\n",
    "                                dtype=tf.float32,\n",
    "                                )\n",
    "    n = len(y_pred)\n",
    "    y = tf.cast(tf.expand_dims(y_pred,0),dtype=tf.int32)\n",
    "    pred = tf.cast(tf.expand_dims(tf.squeeze(y_true,-1),0),dtype=tf.int32)# y_true.squeeze(-1).unsqueeze(0)\n",
    "    if activation is not None:\n",
    "        pred = activation(pred)\n",
    "    wo = (pred - y)**2\n",
    "    we = (pred - tf.transpose(y))**2\n",
    "    \n",
    "    return 1 - (tf.cast(n,dtype=tf.int32) * tf.reduce_sum(wo) / tf.reduce_sum(we))\n",
    "\n",
    "kappa_loss = lambda pred, y: 1 - cont_kappa(pred, y)  # from 0 to 2 instead of 1 to -1\n",
    "class_weights = [0.09759672877367588, 4.099062608494387, 0.08911005670639972, 0.3726420553176716, 0.34158855070786565]\n",
    "class_weights = tf.convert_to_tensor(class_weights,dtype=tf.float32)\n",
    "# class_weights = np.array([0, 4, 0, 0, 0])\n",
    "class grad_Loss(tf.losses.Loss):   \n",
    "    def __init__(self,num_class=5, alpha=class_weights, gamma=2.0, second_loss=kappa_loss, second_mult=0.5):\n",
    "        super(grad_Loss, self).__init__()\n",
    "        \n",
    "        self.alpha = tf.constant(alpha,dtype=tf.float32)# dtype=tf.float32\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.second_loss = second_loss\n",
    "        \n",
    "        self.second_mult = second_mult\n",
    "    def call(self,y_true,y_pred):\n",
    "        y_true = tf.one_hot(tf.cast(y_true, dtype=tf.int32),\n",
    "                                depth=self.num_class,\n",
    "                                dtype=tf.float32,\n",
    "                                )\n",
    "   \n",
    "        alpha_choice = tf.gather(self.alpha,y_true)\n",
    "       \n",
    "        CE_loss = tf.keras.losses.sparse_categorical_crossentropy(y_true,y_pred)\n",
    "        pt = tf.exp(-CE_loss)\n",
    "        \n",
    "        yy = tf.argmax(y_pred,0)\n",
    "        \n",
    "        F_loss = alpha_choice*(1-pt)**self.gamma*CE_loss\n",
    "        F_loss = tf.reduce_mean(F_loss)\n",
    "        \n",
    "        loss = F_loss + self.second_mult*self.second_loss(y_true,y_pred)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb248320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    \"\"\"\n",
    "    :param labels_dense:\n",
    "    :param num_classes:\n",
    "    label number must start from zero,such as:0,1,2,3,4,...\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    labels_dense = np.array(labels_dense)\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    # method one\n",
    "    for index in range(num_labels):\n",
    "        for classindex in range(num_classes):\n",
    "            if labels_dense[index] == classindex:\n",
    "                labels_one_hot[index, classindex] = 1\n",
    "   \n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "class Dataset_Generator():\n",
    "    def __init__(self,\n",
    "                 base_dir = BASE_DIR,\n",
    "                 num_classes = NUM_CLASSES,\n",
    "                 batch_size = BATCH_SIZE,\n",
    "                 height = HEIGHT,\n",
    "                 width = WIDTH,\n",
    "                 epochs = EPOCHS,\n",
    "                ):\n",
    "        \n",
    "        self.base_dir = BASE_DIR\n",
    "        self.num_classes = float(num_classes)\n",
    "        self.batch_size = batch_size\n",
    "        self.height = HEIGHT\n",
    "        self.width = WIDTH\n",
    "        self.epochs = epochs\n",
    "        #self.images_list = []\n",
    "        self.images_list = os.listdir(self.base_dir + \"Training/images/\")\n",
    "        random.shuffle(self.images_list)\n",
    "        \n",
    "    def __del__(self):\n",
    "        print(\"Dataset Generator is destructed\")\n",
    "            \n",
    "    def _preprocessor(self):\n",
    "        \n",
    "        try:\n",
    "            os.mkdir(self.base_dir+\"Training\")\n",
    "            os.mkdir(self.base_dir+\"Test\")\n",
    "            os.mkdir(self.base_dir+\"Training/images\")\n",
    "            os.mkdir(self.base_dir+\"Test/images\")\n",
    "            os.mkdir(self.base_dir+\"Training/masks\")\n",
    "            os.mkdir(self.base_dir+\"Test/masks\")\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        idrid_cnt = diaretdb_cnt = 0 \n",
    "       \n",
    "        image_list = os.listdir(self.base_dir + \"image/\")\n",
    "        for i, file_name in enumerate(image_list):\n",
    "            image_list[i] = file_name.split(\".\")[0]\n",
    "        image_list.sort()\n",
    "\n",
    "        mask_class_dir = [\"MA\", \"HE\", \"EX\", \"SE\"]\n",
    "        mask_file_list = []\n",
    "\n",
    "        for cls in mask_class_dir:\n",
    "            mask_file_list.append(os.listdir(self.base_dir + f\"mask/{cls}\"))\n",
    "\n",
    "        zero_1 = np.zeros([2848, 4288], dtype = np.uint8)\n",
    "        zero_2 = np.zeros([1152, 1500], dtype = np.uint8)\n",
    "\n",
    "        loss_cnt = 0\n",
    "        \n",
    "        for i, file_name in enumerate(image_list):\n",
    "            if \"IDRiD\" in file_name:\n",
    "                zero = zero_1\n",
    "                thres = 1\n",
    "            elif \"image\" in file_name:\n",
    "                zero = zero_2\n",
    "                # [63, 127, 189, 252]\n",
    "                thres = 127\n",
    "\n",
    "            mask_list = []\n",
    "            # 1. mask\n",
    "            for cls in range(4):\n",
    "                \n",
    "                if \"IDRiD\" in file_name:\n",
    "                    mask_file_name = f\"{file_name}_{mask_class_dir[cls]}.tif\"\n",
    "                elif \"image\" in file_name:\n",
    "                    mask_file_name = f\"{file_name}.png\"\n",
    "\n",
    "                if mask_file_name in mask_file_list[cls]:\n",
    "                    mask = cv2.imread(f\"{self.base_dir}mask/{mask_class_dir[cls]}/{mask_file_name}\", 0)\n",
    "                    _, mask = cv2.threshold(mask, thres, 1, cv2.THRESH_BINARY)\n",
    "                else:\n",
    "                    mask = zero\n",
    "                mask_list.append(mask)\n",
    "\n",
    "            # 2. mask fusion\n",
    "            Class_1 = cv2.bitwise_or(mask_list[0], mask_list[1]) * 100\n",
    "            Class_2 = cv2.bitwise_or(mask_list[2], mask_list[3]) * 200\n",
    "            mask = Class_1 + Class_2\n",
    "            del Class_1, Class_2, mask_list\n",
    "\n",
    "            if np.all(mask == zero):\n",
    "                loss_cnt += 1\n",
    "                print(f\"{file_name} has no mask\")\n",
    "            else:\n",
    "                # Binaryzation\n",
    "                if \"IDRiD\" in file_name:\n",
    "                    file_name = f\"{file_name}.jpg\"\n",
    "                elif \"image\" in file_name:\n",
    "                    file_name = f\"{file_name}.png\"\n",
    "                img = cv2.imread(f\"{self.base_dir}image/{file_name}\")\n",
    "\n",
    "                if \"IDRiD\" in file_name:\n",
    "                    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "                    if i==3 or i == 10:\n",
    "                        thres = 10\n",
    "                    else:\n",
    "                        thres = 30\n",
    "\n",
    "                    _, binary_img = cv2.threshold(gray_img, thres, 255, cv2.THRESH_BINARY)\n",
    "                    del gray_img\n",
    "\n",
    "                    contours, hierachy = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "                    x_min = np.min(contours[-1], axis = 0)\n",
    "                    x_max = np.max(contours[-1], axis = 0)\n",
    "                    x_min, x_max = x_min[0][0], x_max[0][0]\n",
    "                    del contours, hierachy\n",
    "\n",
    "                    img = img[:, x_min:x_max+1]\n",
    "                    mask = mask[:, x_min:x_max+1]\n",
    "\n",
    "                    if (x_max-x_min)/2848 >= 1.25:\n",
    "                        pad_left, pad_right = 0, 0\n",
    "                    else:\n",
    "                        pad_left, pad_right = 200, 200\n",
    "\n",
    "                    img = cv2.copyMakeBorder(img, 500, 500, pad_left, pad_right, cv2.BORDER_CONSTANT,value=0)\n",
    "                    mask = cv2.copyMakeBorder(mask, 500, 500, pad_left, pad_right, cv2.BORDER_CONSTANT,value=0)\n",
    "\n",
    "                elif \"image\" in file_name:\n",
    "                    img = cv2.copyMakeBorder(img, 174, 174, 0, 0, cv2.BORDER_CONSTANT,value=0)\n",
    "                    mask = cv2.copyMakeBorder(mask, 174, 174, 0, 0, cv2.BORDER_CONSTANT,value=0)\n",
    "\n",
    "                img = cv2.resize(img, dsize=(self.height, self.width), interpolation=cv2.INTER_AREA)\n",
    "                mask = cv2.resize(mask, dsize=(self.height, self.width), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                if \"IDRiD\" in file_name and idrid_cnt < 60:\n",
    "                    cv2.imwrite(f'{self.base_dir}Training/images/{file_name}', img)\n",
    "                    cv2.imwrite(f'{self.base_dir}Training/masks/{file_name}', mask)\n",
    "#                     cv2.imwrite(f'{self.base_dir}Training/grad_label/{file_name}', grad)# cc\n",
    "                    idrid_cnt += 1\n",
    "\n",
    "                elif \"IDRiD\" in file_name and idrid_cnt >= 60:\n",
    "                    cv2.imwrite(f'{self.base_dir}Test/images/{file_name}', img)\n",
    "                    cv2.imwrite(f'{self.base_dir}Test/masks/{file_name}', mask)\n",
    "#                     cv2.imwrite(f'{self.base_dir}Training/grad_label/{file_name}', grad)# cc\n",
    "                    idrid_cnt += 1\n",
    "\n",
    "                elif \"image\" in file_name and diaretdb_cnt < 40:\n",
    "                    cv2.imwrite(f'{self.base_dir}Training/images/{file_name}', img)\n",
    "                    cv2.imwrite(f'{self.base_dir}Training/masks/{file_name}', mask)\n",
    "#                     cv2.imwrite(f'{self.base_dir}Training/grad_label/{file_name}', grad)# cc\n",
    "                    diaretdb_cnt += 1\n",
    "\n",
    "                elif \"image\" in file_name and diaretdb_cnt >= 40:\n",
    "                    cv2.imwrite(f'{self.base_dir}Test/images/{file_name}', img)\n",
    "                    cv2.imwrite(f'{self.base_dir}Test/masks/{file_name}', mask)\n",
    "#                     cv2.imwrite(f'{self.base_dir}Training/grad_label/{file_name}', grad)# cc\n",
    "                    diaretdb_cnt += 1\n",
    "\n",
    "                print(f\"{file_name} completed!\")\n",
    "        self.images_list = os.listdir(self.base_dir + \"Training/images/\")\n",
    "        random.shuffle(self.images_list)\n",
    "        print(f\"Preprocessing completed!. Number of no mask data : {loss_cnt}\")\n",
    "        \n",
    "    \n",
    "    def _Image_Reshape(self, image, mask, grad):     \n",
    "        \n",
    "#         print(image.shape)# (1024,1024,3)\n",
    "        \n",
    "        image = np.reshape(image, ((self.batch_size,) + image.shape))\n",
    "\n",
    "        \n",
    "        mask = np.reshape(mask, ((self.batch_size,) + mask.shape))\n",
    "        \n",
    "#         grad = np.reshape(grad,((self.batch_size,) + np.array(grad).shape))\n",
    "        \n",
    "        grad = LabelGenerator(image,grad)\n",
    "\n",
    "#         print(\"np.array(mask/200.\",np.array(mask/200.))# np.array(mask/200. (1, 1024, 1024)#change mask to 100 will add lesions\n",
    "#         print(\"np.array(image/255.\",np.array(image/255))# np.array(image/255. (1, 1024, 1024, 3)\n",
    "#         print(grad.shape)\n",
    "        return ({'ccinput':np.array(image/255.)}, {'grad5_Conv_ReLU':np.array(mask/200),'grad':grad})# cc\n",
    "    \n",
    "    def train_generator(self, k):\n",
    "        \"\"\"\n",
    "        Training Data Augmentation\n",
    "        \"\"\"\n",
    "      \n",
    "        if self.images_list:\n",
    "            pass\n",
    "        else:\n",
    "            self._preprocessor()\n",
    "        x_center, y_center = self.width/2, self.height/2\n",
    "       \n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            \n",
    "            # cc add grad_labels\n",
    "            grad_train = pd.read_csv(self.base_dir+'Training/grad_label/id_dia.csv')\n",
    "            x = grad_train['id_code']\n",
    "            y = grad_train['diagnosis']\n",
    "            x, y = shuffle(x, y)\n",
    "            # cc get class stats\n",
    "            n_classes = int(y.max()+1)\n",
    "            # cc print(n_classes)# \n",
    "            class_weights = len(y) / grad_train.groupby('diagnosis').size().values.ravel()  # we can use this to balance our loss function\n",
    "            class_weights *= n_classes / class_weights.sum()\n",
    "#             print('class_weights:', class_weights.tolist())\n",
    "            \n",
    "            for i, file_name in enumerate(self.images_list):\n",
    "                grad = []\n",
    "                if 20*k-20 <= i < 20*k:\n",
    "                    pass\n",
    "                else:\n",
    "             \n",
    "                    img = cv2.imread(f\"{self.base_dir}Training/images/{file_name}\")\n",
    "                   \n",
    "\n",
    "                    mask = cv2.imread(f\"{self.base_dir}Training/masks/{file_name}\", 0)\n",
    "                          \n",
    "                    for i in range(len(x.values)):# cc\n",
    "                        if(file_name == x.values[i]):\n",
    "                            grad.append(y.values[i])\n",
    "                    \n",
    "                    yield self._Image_Reshape(img, mask, grad)\n",
    "                    \n",
    "                    flip_img = cv2.flip(img, 1)\n",
    "                    \n",
    "                    flip_mask = cv2.flip(mask, 1)\n",
    "                    yield self._Image_Reshape(flip_img, flip_mask, grad)\n",
    "\n",
    "                    for degree in range(90, 360, 90):\n",
    "                        matrix = cv2.getRotationMatrix2D((x_center, y_center), degree, 1)\n",
    "\n",
    "                        rot_img = cv2.warpAffine(img, matrix, (self.width, self.height))\n",
    "                    \n",
    "                        rot_mask = cv2.warpAffine(mask, matrix, (self.width, self.height))\n",
    "                        yield self._Image_Reshape(rot_img, rot_mask, grad)\n",
    "\n",
    "                        rot_flip_img = cv2.warpAffine(flip_img, matrix, (self.width, self.height))\n",
    "                    \n",
    "                        rot_flip_mask = cv2.warpAffine(flip_mask, matrix, (self.width, self.height))\n",
    "                        yield self._Image_Reshape(rot_flip_img, rot_flip_mask, grad)\n",
    "\n",
    "\n",
    "    def valid_generator(self, k):\n",
    "        \"\"\"\n",
    "        Validataion Data Augmentation\n",
    "        \"\"\"\n",
    "        x_center, y_center = self.width/2, self.height/2\n",
    "        \n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "\n",
    "            grad_train = pd.read_csv(self.base_dir+'Training/grad_label/id_dia.csv')\n",
    "            x = grad_train['id_code']\n",
    "            y = grad_train['diagnosis']\n",
    "            x, y = shuffle(x, y)\n",
    "            # cc get class stats\n",
    "            n_classes = int(y.max()+1)\n",
    "            # cc print(n_classes)# \n",
    "            class_weights = len(y) / grad_train.groupby('diagnosis').size().values.ravel()  # we can use this to balance our loss function\n",
    "            class_weights *= n_classes / class_weights.sum()\n",
    "#             print('class_weights:', class_weights.tolist())\n",
    "#             class_weights: [0.09759672877367588, 4.099062608494387, 0.08911005670639972, 0.3726420553176716, 0.34158855070786565]\n",
    "            \n",
    "            for i, file_name in enumerate(self.images_list):\n",
    "                grad = []\n",
    "                if (20*k-20) <= i < 20*k:\n",
    "\n",
    "                    img = cv2.imread(f\"{self.base_dir}Training/images/{file_name}\")\n",
    "                   \n",
    "                    mask = cv2.imread(f\"{self.base_dir}Training/masks/{file_name}\", 0)\n",
    "\n",
    "                    for i in range(len(x.values)):# cc\n",
    "                        if(file_name == x.values[i]):\n",
    "                            grad.append(y.values[i])\n",
    "                            \n",
    "                    yield self._Image_Reshape(img, mask, grad)\n",
    "                 \n",
    "                   \n",
    "                    flip_img = cv2.flip(img, 1)\n",
    "                   \n",
    "                    flip_mask = cv2.flip(mask, 1)\n",
    "                    yield self._Image_Reshape(flip_img, flip_mask,grad)\n",
    "\n",
    "                    for degree in range(90, 360, 90):\n",
    "                        matrix = cv2.getRotationMatrix2D((x_center, y_center), degree, 1)\n",
    "                            \n",
    "                        \n",
    "                        rot_img = cv2.warpAffine(img, matrix, (self.width, self.height))\n",
    "                        \n",
    "                        rot_mask = cv2.warpAffine(mask, matrix, (self.width, self.height))\n",
    "                        yield self._Image_Reshape(rot_img, rot_mask, grad)\n",
    "\n",
    "                        \n",
    "                        rot_flip_img = cv2.warpAffine(flip_img, matrix, (self.width, self.height))\n",
    "                       \n",
    "                        rot_flip_mask = cv2.warpAffine(flip_mask, matrix, (self.width, self.height))\n",
    "                        yield self._Image_Reshape(rot_flip_img, rot_flip_mask, grad)\n",
    "\n",
    "\n",
    "                \n",
    "    def test_generator(self):\n",
    "        images_list = os.listdir(self.base_dir + \"Test/images/\")\n",
    "\n",
    "        grad_test = pd.read_csv(self.base_dir+'Test/grad_label/id_dia.csv')\n",
    "        x = grad_test['id_code']\n",
    "        y = grad_test['diagnosis']\n",
    "        x, y = shuffle(x, y)\n",
    "        # cc get class stats\n",
    "        n_classes = int(y.max()+1)\n",
    "        # cc print(n_classes)# \n",
    "        class_weights = len(y) / grad_test.groupby('diagnosis').size().values.ravel()  # we can use this to balance our loss function\n",
    "        class_weights *= n_classes / class_weights.sum()\n",
    "#         print('class_weights:', class_weights.tolist())\n",
    "            \n",
    "        for i, file_name in enumerate(images_list):\n",
    "            grad = []\n",
    "           \n",
    "            img = cv2.imread(f\"{self.base_dir}Test/images/{file_name}\")\n",
    "        \n",
    "            mask = cv2.imread(f\"{self.base_dir}Test/masks/{file_name}\", 0)\n",
    "            \n",
    "#             cv2.namedWindow(\"mask\")     \n",
    "#             cv2.imshow(\"mask\", mask)    \n",
    "#             cv2.waitKey()               \n",
    "#             cv2.destroyAllWindows()               \n",
    "            \n",
    "            for i in range(len(x.values)):# cc\n",
    "                \n",
    "                if(file_name == x.values[i]):\n",
    "                    grad.append(y.values[i])           \n",
    "                            \n",
    "            yield self._Image_Reshape(img, mask,grad)\n",
    "dataset = Dataset_Generator()\n",
    "\n",
    "gen = dataset.test_generator()\n",
    "\n",
    "result = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training dataset check\n",
    "dataset = Dataset_Generator()\n",
    "\n",
    "gen = dataset.train_generator(1)\n",
    "for i in range(720 * 4):\n",
    "    result = next(gen)\n",
    "    \n",
    "    img = 'input'\n",
    "    mask = 'mask'\n",
    "    \n",
    "#     grad = result[3][0]# \n",
    "#     print(grad)\n",
    "#     img=np.expand_dims(img,axis=0)\n",
    "   \n",
    "#     print(img.shape)\n",
    "\n",
    "    fig = plt.figure(i, figsize = (10,10))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Image')\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(mask, cmap = \"bone\")\n",
    "    ax2.set_title('Ground Truth Mask')\n",
    "    ax2.axis(\"off\")\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation dataset check\n",
    "gen = dataset.valid_generator(1)\n",
    "for i in range(720):\n",
    "    result = next(gen)\n",
    "    img, mask = result[0][0], result[1][0]\n",
    "    \n",
    "#     grad = result[2][0]\n",
    "#     print(grad)\n",
    "    \n",
    "    fig = plt.figure(i, figsize = (10,10))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Image')\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(mask, cmap = \"bone\")\n",
    "    ax2.set_title('Ground Truth Mask')\n",
    "    ax2.axis(\"off\")\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13362d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test dataset\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "                    dataset.test_generator,\n",
    "                    (tf.float32, tf.int32),\n",
    "                    (tf.TensorShape([1, HEIGHT, WIDTH, 3]), tf.TensorShape([1,  HEIGHT, WIDTH])),\n",
    "                    )\n",
    "\n",
    "del dataset\n",
    "\n",
    "## Check Test set test\n",
    "for i, element in enumerate(test_dataset):\n",
    "    img = element[0][0].numpy()\n",
    "    mask = element[1][0].numpy()\n",
    "    fig = plt.figure(i, figsize = (10,10))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Image')\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(mask, cmap = \"bone\")\n",
    "    ax2.set_title('Ground Truth Mask')\n",
    "    ax2.axis(\"off\")\n",
    "    \n",
    "    if i == 3:\n",
    "        break\n",
    "    plt.show()\n",
    "\n",
    "del gen, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = tf.keras.Input(shape=(1024, 1024, 3), name=\"ccinput\")\n",
    "dataset = Dataset_Generator()\n",
    "model = Unet()\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "                dataset.test_generator,\n",
    "                ({'ccinput': tf.float32},{ 'grad5_Conv_ReLU':tf.int32,  'grad':tf.int32}),# cc\n",
    "                ({'ccinput':tf.TensorShape([1, HEIGHT, WIDTH, 3])}, { 'grad5_Conv_ReLU':tf.TensorShape([1,  HEIGHT, WIDTH]), 'grad':tf.TensorShape([1,5])}),\n",
    "                )\n",
    "predictions,classifications = model(input_image, training = True)\n",
    "# print(classifications)# shape=(None, 5)\n",
    "inference_model = tf.keras.Model(inputs=input_image, outputs=[predictions,classifications])# cc\n",
    "\n",
    "for i,test in enumerate(test_dataset):\n",
    "    img,mask_grad= test  \n",
    "    prediction,classify = inference_model.predict(img)\n",
    "    \n",
    "    \n",
    "    img = img[\"ccinput\"][0].numpy()\n",
    "    mask = mask_grad['grad5_Conv_ReLU'][0].numpy()\n",
    "    \n",
    "    prediction = prediction[0]\n",
    "    prediction = tf.math.argmax(prediction, -1)\n",
    "    prediction = prediction.numpy()\n",
    "\n",
    "    fig = plt.figure(10, figsize = (20,20))\n",
    "    ax1 = fig.add_subplot(1, 3, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Image')\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 3, 2)\n",
    "    ax2.imshow(mask)\n",
    "    ax2.set_title('Ground Truth Mask')\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    ax3 = fig.add_subplot(1, 3, 3)\n",
    "    ax3.imshow(prediction)\n",
    "    ax3.set_title('Prediction')\n",
    "    ax3.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2fcfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL():\n",
    "    def __init__(self,\n",
    "                 model_dir = MODEL_DIR,\n",
    "                 batch_size = BATCH_SIZE,\n",
    "                 width = WIDTH,\n",
    "                 height = HEIGHT,\n",
    "                 k = 0,\n",
    "                ):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.loss_fn = generalized_dice_loss_fun()#CategoricalFocalLoss()\n",
    "         \n",
    "        self.loss_fc = CategoricalFocalLoss2()#grad_Loss()\n",
    "        \n",
    "        self.optimizer =  tf.keras.optimizers.Adam(learning_rate=0.00005)# 0.00005\n",
    "        self.generator = Dataset_Generator()\n",
    "        self.model_dir = MODEL_DIR\n",
    "        self.optimal_k = k\n",
    "        \n",
    "\n",
    "        self.test_dataset = tf.data.Dataset.from_generator(\n",
    "                        self.generator.test_generator,\n",
    "                        ({'ccinput': tf.float32},{ 'grad5_Conv_ReLU':tf.int32,  'grad':tf.int32}),# cc tf.int32\n",
    "                        ({'ccinput':tf.TensorShape([1, HEIGHT, WIDTH, 3])}, { 'grad5_Conv_ReLU':tf.TensorShape([1,  HEIGHT, WIDTH]), 'grad':tf.TensorShape([1,5])}),\n",
    "                        )\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    def __del__(self):\n",
    "        print(\"MODEL is destructed\")\n",
    "        \n",
    "\n",
    "    def Run_training(self, epochs=EPOCHS):        \n",
    "        print(\"Model Complie....\")        \n",
    "        \n",
    "        # K-fold: k = 5\n",
    "        K = 5\n",
    "        mean_Dice = mean_IoU = 0\n",
    "        DiceIoU_list = []\n",
    "        for k in range(1, K+1):\n",
    "            model = Unet()\n",
    "            model.compile(loss = {'grad5_Conv_ReLU':self.loss_fn,'grad':self.loss_fc} ,#'categorical_crossentropy'   \n",
    "                          loss_weights = [1,0.8],\n",
    "                          optimizer = self.optimizer,\n",
    "                          metrics = {'grad5_Conv_ReLU':Dice,\"grad\":Dice_class}#Dice_class\\Classify_ac Jaccard sparse_categorical_accuracy; acc;\n",
    "#                           metrics = [\"accuracy\"]\n",
    "                          )\n",
    "            callbacks_list = [tf.keras.callbacks.ModelCheckpoint(\n",
    "                                        filepath=os.path.join(\n",
    "                                            f\"{self.model_dir}U-Net_{k}.h5\"),\n",
    "                                        monitor=\"val_loss\",\n",
    "#                                         monitor=\"val_block5_Conv_ReLU_Dice\",\n",
    "                                        mode = \"min\",\n",
    "                                        save_best_only=True,\n",
    "                                        save_weights_only=False,\n",
    "                                        verbose=1,\n",
    "                                        ),\n",
    "                              tf.keras.callbacks.EarlyStopping(\n",
    "                                        monitor = 'val_loss',\n",
    "#                                         monitor=\"val_block5_Conv_ReLU_Dice\",\n",
    "                                        mode = \"min\",\n",
    "                                        min_delta = 0.01,\n",
    "                                        patience = 5,\n",
    "                                        )\n",
    "                              ]\n",
    "            print(f\"{k}th fold Start Training....\")\n",
    "            \n",
    "      \n",
    "        \n",
    "            history = model.fit(self.generator.train_generator(k),\n",
    "                                steps_per_epoch = (K-1) * 20 * 8,\n",
    "                                validation_data = self.generator.valid_generator(k),\n",
    "                                validation_steps = 20 * 8,\n",
    "                                callbacks = callbacks_list,\n",
    "                                epochs = epochs,\n",
    "                                batch_size = self.batch_size,\n",
    "#                                 shuffle = True,\n",
    "                                )\n",
    "            \n",
    "            loss = history.history['loss']\n",
    "            val_loss = history.history['val_loss']\n",
    "            dice = history.history[\"grad5_Conv_ReLU_Dice\"]\n",
    "            val_dice = history.history[\"val_grad5_Conv_ReLU_Dice\"]\n",
    "            iou = history.history[\"grad_Dice_class\"]\n",
    "            val_iou = history.history[\"val_grad_Dice_class\"]\n",
    "            \n",
    "            DiceIoU_list.append( val_dice[-1] + val_iou[-1] )\n",
    "            mean_Dice += val_dice[-1]\n",
    "            mean_IoU += val_iou[-1]\n",
    "\n",
    "            epochs_range = range(len(loss))\n",
    "            \n",
    "            plt.figure(k, figsize=(15, 5))\n",
    "\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.plot(epochs_range, loss, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.title('Loss')\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.plot(epochs_range, dice, label='Training Dice')\n",
    "            plt.plot(epochs_range, val_dice, label='Validation Dice')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.title('Dice Coefficient')\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.plot(epochs_range, iou, label='Training CDice')\n",
    "            plt.plot(epochs_range, val_iou, label='Validation CDice')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.title('Classify_metrics')# IoU\n",
    "            plt.show()\n",
    "\n",
    "            input_image = tf.keras.Input(shape=(self.width, self.height, 3), name=\"ccinput\")# \"image\"\n",
    "            predictions,classifications = model(input_image, training = True)\n",
    "            inference_model = tf.keras.Model(inputs=input_image, outputs=[predictions,classifications])# cc\n",
    "\n",
    "            for i, test in enumerate(self.test_dataset):\n",
    "                img,mask_grad= test  \n",
    "                prediction,classify = inference_model.predict(img)\n",
    "\n",
    "                img = img[\"ccinput\"][0].numpy()\n",
    "                mask = mask_grad['grad5_Conv_ReLU'][0].numpy()\n",
    "\n",
    "                prediction = prediction[0]\n",
    "                prediction = tf.math.argmax(prediction, -1)\n",
    "                prediction = prediction.numpy()\n",
    "\n",
    "                fig = plt.figure(10, figsize = (20,20))\n",
    "                ax1 = fig.add_subplot(1, 3, 1)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                ax1.imshow(img)\n",
    "                ax1.set_title('Image')\n",
    "                ax1.axis(\"off\")\n",
    "\n",
    "                ax2 = fig.add_subplot(1, 3, 2)\n",
    "                ax2.imshow(mask)\n",
    "                ax2.set_title('Ground Truth Mask')\n",
    "                ax2.axis(\"off\")\n",
    "\n",
    "                ax3 = fig.add_subplot(1, 3, 3)\n",
    "                ax3.imshow(prediction)\n",
    "                ax3.set_title('Prediction')\n",
    "                ax3.axis(\"off\")\n",
    "                plt.show()\n",
    "\n",
    "                if i == 1:\n",
    "                    break\n",
    "            del model\n",
    "        print(\"Training End\\n\\n\")\n",
    "        self.optimal_k = DiceIoU_list.index(max(DiceIoU_list)) + 1\n",
    "        print(f\"K-Fold Cross Validation Result\\nmDice : {mean_Dice*20:.3f}, mIoU : {mean_IoU*20:.3f}, Optimal_K : {self.optimal_k}\\n\\n\")\n",
    "\n",
    "        \n",
    "    def Evaluation(self, num_sample):\n",
    "        input_image = tf.keras.Input(shape=(self.width, self.height, 3), name=\"ccinput\")# \"image\"\n",
    "        model = Unet()\n",
    "        model.load_weights(\n",
    "            f\"{self.model_dir}U-Net_5.h5\")# {self.optimal_k}\n",
    "\n",
    "#         model.compile(loss = self.loss_fn, \n",
    "#                       optimizer = self.optimizer,\n",
    "#                       metrics = [Dice, Jaccard]\n",
    "#                       )\n",
    "        model.compile(loss = {'grad5_Conv_ReLU':self.loss_fn,'grad':self.loss_fc} ,#'categorical_crossentropy'   \n",
    "                                  loss_weights = [1,0.8],\n",
    "                                  optimizer = self.optimizer,\n",
    "                                  metrics = {'grad5_Conv_ReLU':Dice,\"grad\":Dice_class}# Jaccard\n",
    "        #                           metrics = [\"accuracy\"]\n",
    "                                  )\n",
    "        dice = model.evaluate(self.test_dataset, batch_size = self.batch_size, verbose = 1)#  _, dice, iou\n",
    "\n",
    "        predictions,classifications = model(input_image, training=True)\n",
    "        inference_model = tf.keras.Model(inputs=input_image, outputs=[predictions,classifications])\n",
    "        \n",
    "#         print(predictions.shape)# (None, 1024, 1024, 3)\n",
    "        \n",
    "        \n",
    "      # cc  \n",
    "        print(\"Display predictions\")\n",
    "        for i, test in enumerate(self.test_dataset):\n",
    "            img, mask_grad= test\n",
    "            prediction,classify = inference_model.predict(img)\n",
    "            \n",
    "            \n",
    "            \n",
    "            img = img[\"ccinput\"][0].numpy()\n",
    "            mask = mask_grad[\"grad5_Conv_ReLU\"][0].numpy()\n",
    "            \n",
    "#             mask1=to_categorical(mask,3)\n",
    "            fpr = dict()\n",
    "            tpr = dict()\n",
    "            roc_auc = dict()\n",
    "            \n",
    "\n",
    "            prediction = prediction[0]\n",
    "           \n",
    "            prediction = tf.math.argmax(prediction, -1)\n",
    "            prediction = prediction.numpy()       \n",
    "            \n",
    "            fig = plt.figure(i, figsize = (20,20))\n",
    "            ax1 = fig.add_subplot(1, 3, 1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax1.imshow(img)\n",
    "            ax1.set_title('Image')\n",
    "            ax1.axis(\"off\")\n",
    "\n",
    "            ax2 = fig.add_subplot(1, 3, 2)\n",
    "            ax2.imshow(mask)\n",
    "            ax2.set_title('Ground Truth Mask')\n",
    "            ax2.axis(\"off\")\n",
    "\n",
    "            ax3 = fig.add_subplot(1, 3, 3)\n",
    "            ax3.imshow(prediction)\n",
    "            ax3.set_title('Prediction')\n",
    "            ax3.axis(\"off\")\n",
    "            plt.show()\n",
    "            \n",
    "#             ax4 = fig.add_subplot(1, 4, 3)\n",
    "#             ax4.plot(fpr_1, tpr_1, 'r', label='AUC = %0.2f' % auc1)\n",
    "\n",
    "#             ax4.legend(loc='lower right')\n",
    "#             ax4.plot([0, 1], [0, 1], 'r--')\n",
    "#             # plt.xlim([0, 1])  # the range of x-axis\n",
    "#             # plt.ylim([0, 1])  # the range of y-axis\n",
    "#             ax4.xlabel('False Positive Rate')  # the name of x-axis\n",
    "#             ax4.ylabel('True Positive Rate')  # the name of y-axis\n",
    "#             ax4.title('Receiver operating characteristic example')  # the title of figure\n",
    "            \n",
    "            \n",
    "            plt.show()   \n",
    "\n",
    "#             print(hist_info(3,prediction,mask))\n",
    "            \n",
    "            if i == num_sample:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))# sess.run(......)\n",
    "\n",
    "\n",
    "vgg_CFL = MODEL()\n",
    "vgg_CFL.Run_training()\n",
    "sess.run(vgg_CFL.Evaluation(num_sample = -1))\n",
    "del vgg_CFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c418121",
   "metadata": {},
   "source": [
    "Model: \"model_57\"\n",
    "__________________________________________________________________________________________________\n",
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "ccinput (InputLayer)            [(None, 1024, 1024,  0                                            \n",
    "__________________________________________________________________________________________________\n",
    "model_56 (Functional)           [(None, 32, 32, 512) 14714688    ccinput[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "ccblock0_Conv0 (Conv2D)         (None, 32, 32, 512)  2359808     model_56[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "ccblock0_BN0 (BatchNormalizatio (None, 32, 32, 512)  2048        ccblock0_Conv0[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock0_ReLU0 (ReLU)           (None, 32, 32, 512)  0           ccblock0_BN0[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock0_Conv1 (Conv2D)         (None, 32, 32, 512)  2359808     ccblock0_ReLU0[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock0_BN1 (BatchNormalizatio (None, 32, 32, 512)  2048        ccblock0_Conv1[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock0_ReLU1 (ReLU)           (None, 32, 32, 512)  0           ccblock0_BN1[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock1_UpSampling0 (UpSamplin (None, 64, 64, 512)  0           ccblock0_ReLU1[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock1_Conv0 (Conv2D)         (None, 64, 64, 512)  1049088     ccblock1_UpSampling0[0][0]       \n",
    "__________________________________________________________________________________________________\n",
    "ccblock1_BN0 (BatchNormalizatio (None, 64, 64, 512)  2048        ccblock1_Conv0[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock1_ReLU0 (ReLU)           (None, 64, 64, 512)  0           ccblock1_BN0[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock1_concat (Concatenate)   (None, 64, 64, 1024) 0           ccblock1_ReLU0[0][0]             \n",
    "                                                                 model_56[0][1]                   \n",
    "__________________________________________________________________________________________________\n",
    "ccblock1_Conv2 (Conv2D)         (None, 64, 64, 256)  2359552     ccblock1_concat[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "ccblock1_BN2 (BatchNormalizatio (None, 64, 64, 256)  1024        ccblock1_Conv2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock1_ReLU2 (ReLU)           (None, 64, 64, 256)  0           ccblock1_BN2[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock2_UpSampling0 (UpSamplin (None, 128, 128, 256 0           ccblock1_ReLU2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock2_Conv0 (Conv2D)         (None, 128, 128, 256 262400      ccblock2_UpSampling0[0][0]       \n",
    "__________________________________________________________________________________________________\n",
    "ccblock2_BN0 (BatchNormalizatio (None, 128, 128, 256 1024        ccblock2_Conv0[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock2_ReLU0 (ReLU)           (None, 128, 128, 256 0           ccblock2_BN0[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock2_concat (Concatenate)   (None, 128, 128, 768 0           ccblock2_ReLU0[0][0]             \n",
    "                                                                 model_56[0][2]                   \n",
    "__________________________________________________________________________________________________\n",
    "ccblock2_Conv2 (Conv2D)         (None, 128, 128, 128 884864      ccblock2_concat[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "ccblock2_BN2 (BatchNormalizatio (None, 128, 128, 128 512         ccblock2_Conv2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock2_ReLU2 (ReLU)           (None, 128, 128, 128 0           ccblock2_BN2[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock3_UpSampling0 (UpSamplin (None, 256, 256, 128 0           ccblock2_ReLU2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock3_Conv0 (Conv2D)         (None, 256, 256, 128 65664       ccblock3_UpSampling0[0][0]       \n",
    "__________________________________________________________________________________________________\n",
    "ccblock3_BN0 (BatchNormalizatio (None, 256, 256, 128 512         ccblock3_Conv0[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock3_ReLU0 (ReLU)           (None, 256, 256, 128 0           ccblock3_BN0[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock3_concat (Concatenate)   (None, 256, 256, 384 0           ccblock3_ReLU0[0][0]             \n",
    "                                                                 model_56[0][3]                   \n",
    "__________________________________________________________________________________________________\n",
    "ccblock3_Conv2 (Conv2D)         (None, 256, 256, 64) 221248      ccblock3_concat[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "ccblock3_BN2 (BatchNormalizatio (None, 256, 256, 64) 256         ccblock3_Conv2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock3_ReLU2 (ReLU)           (None, 256, 256, 64) 0           ccblock3_BN2[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock4_UpSampling0 (UpSamplin (None, 512, 512, 64) 0           ccblock3_ReLU2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock4_Conv0 (Conv2D)         (None, 512, 512, 64) 16448       ccblock4_UpSampling0[0][0]       \n",
    "__________________________________________________________________________________________________\n",
    "ccblock4_BN0 (BatchNormalizatio (None, 512, 512, 64) 256         ccblock4_Conv0[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock4_ReLU0 (ReLU)           (None, 512, 512, 64) 0           ccblock4_BN0[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock4_concat (Concatenate)   (None, 512, 512, 192 0           ccblock4_ReLU0[0][0]             \n",
    "                                                                 model_56[0][4]                   \n",
    "__________________________________________________________________________________________________\n",
    "ccblock4_Conv2 (Conv2D)         (None, 512, 512, 32) 55328       ccblock4_concat[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "ccblock4_BN2 (BatchNormalizatio (None, 512, 512, 32) 128         ccblock4_Conv2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock4_ReLU2 (ReLU)           (None, 512, 512, 32) 0           ccblock4_BN2[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock5_UpSampling0 (UpSamplin (None, 1024, 1024, 3 0           ccblock4_ReLU2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock5_Conv0 (Conv2D)         (None, 1024, 1024, 3 4128        ccblock5_UpSampling0[0][0]       \n",
    "__________________________________________________________________________________________________\n",
    "ccblock5_BN0 (BatchNormalizatio (None, 1024, 1024, 3 128         ccblock5_Conv0[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "ccblock5_ReLU0 (ReLU)           (None, 1024, 1024, 3 0           ccblock5_BN0[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "ccblock5_concat (Concatenate)   (None, 1024, 1024, 9 0           ccblock5_ReLU0[0][0]             \n",
    "                                                                 model_56[0][5]                   \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_37 (MaxPooling2D) (None, 1, 1, 512)    0           model_56[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "ccblock5_Conv2 (Conv2D)         (None, 1024, 1024, 1 13840       ccblock5_concat[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "ccflatten (Flatten)             (None, 512)          0           max_pooling2d_37[0][0]           \n",
    "__________________________________________________________________________________________________\n",
    "ccblock5_BN2 (BatchNormalizatio (None, 1024, 1024, 1 64          ccblock5_Conv2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "dense_85 (Dense)                (None, 32)           16416       ccflatten[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "ccblock5_ReLU2 (ReLU)           (None, 1024, 1024, 1 0           ccblock5_BN2[0][0]               \n",
    "__________________________________________________________________________________________________\n",
    "re_lu_61 (ReLU)                 (None, 32)           0           dense_85[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "grad5_Conv_ReLU (Conv2D)        (None, 1024, 1024, 3 51          ccblock5_ReLU2[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "grad (Dense)                    (None, 5)            165         re_lu_61[0][0]                   \n",
    "==================================================================================================\n",
    "Total params: 24,393,544\n",
    "Trainable params: 24,388,520\n",
    "Non-trainable params: 5,024\n",
    "__________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3bd7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
